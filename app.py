import streamlit as st
import os
import chromadb
from PIL import Image
import numpy as np
import tempfile
import shutil

from model_loader import EmbeddingModel
from utils import extract_text_with_page_numbers, move_file_to_category

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤šæ¨¡æ€ AI åŠ©æ‰‹", layout="wide", page_icon="ğŸ¤–")

# --- æ ¸å¿ƒèµ„æºåŠ è½½---
@st.cache_resource
def load_models():
    """åŠ è½½æ¨¡å‹ï¼Œåªæ‰§è¡Œä¸€æ¬¡"""
    return EmbeddingModel()

@st.cache_resource
def load_db():
    """è¿æ¥æ•°æ®åº“ï¼Œåªæ‰§è¡Œä¸€æ¬¡"""
    client = chromadb.PersistentClient(path="./db")
    paper_collection = client.get_or_create_collection(name="papers")
    image_collection = client.get_or_create_collection(name="images")
    return paper_collection, image_collection

# åˆå§‹åŒ–åŠ è½½
try:
    with st.spinner('æ­£åœ¨åŠ è½½ AI æ¨¡å‹ (MiniLM & CLIP)... è¯·ç¨å€™'):
        model_handler = load_models()
        paper_collection, image_collection = load_db()
    st.success("æ¨¡å‹ä¸æ•°æ®åº“åŠ è½½å®Œæ¯•ï¼")
except Exception as e:
    st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    st.stop()

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ¤– AI Agent æ§åˆ¶å°")
app_mode = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", ["ğŸ“„ è®ºæ–‡ä¸Šä¼ ä¸åˆ†ç±»", "ğŸ” è¯­ä¹‰æ–‡çŒ®æœç´¢", "ğŸ–¼ï¸ ä»¥æ–‡æœå›¾"])

# --- åŠŸèƒ½ 1: è®ºæ–‡ä¸Šä¼ ä¸åˆ†ç±» ---
if app_mode == "ğŸ“„ è®ºæ–‡ä¸Šä¼ ä¸åˆ†ç±»":
    st.title("ğŸ“„ æ™ºèƒ½è®ºæ–‡å½’æ¡£")
    st.markdown("ä¸Šä¼  PDFï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æå†…å®¹ã€åˆ†ç±»å¹¶å»ºç«‹è¯­ä¹‰ç´¢å¼•ã€‚")

    # 1. è¯é¢˜è®¾ç½®
    topics_input = st.text_input("è®¾ç½®åˆ†ç±»ä¸»é¢˜ (ç”¨é€—å·åˆ†éš”)", "CV,NLP,Agent,RL,Backbone")
    
    # 2. æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader("ä¸Šä¼  PDF è®ºæ–‡", type=["pdf"], accept_multiple_files=True)

    if st.button("å¼€å§‹å¤„ç†") and uploaded_files:
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, uploaded_file in enumerate(uploaded_files):
            status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}...")

            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            # 1. æå–æ–‡æœ¬
            chunks = extract_text_with_page_numbers(tmp_path)
            
            if not chunks:
                st.warning(f"æ–‡ä»¶ {uploaded_file.name} æ— æ³•æå–æ–‡æœ¬ã€‚")
                os.unlink(tmp_path)
                continue

            # 2. ç¡®å®šåˆ†ç±»
            summary_text = " ".join([c["text"] for c in chunks[:3]])
            summary_vec = model_handler.get_text_embedding(summary_text)

            best_topic = "Uncategorized"
            if topics_input:
                t_list = topics_input.split(',')
                t_vecs = model_handler.text_model.encode(t_list)
                scores = [np.dot(t_v, summary_vec) for t_v in t_vecs]
                best_topic = t_list[np.argmax(scores)]

            # 3. ç§»åŠ¨æ–‡ä»¶åˆ°çœŸå®çš„æ•°æ®ç›®å½•
            target_dir = os.path.join("data", best_topic)
            os.makedirs(target_dir, exist_ok=True)
            final_path = os.path.join(target_dir, uploaded_file.name)

            shutil.copy(tmp_path, final_path)

            # 4. å­˜å…¥æ•°æ®åº“
            ids, docs, vecs, metas = [], [], [], []
            for chunk in chunks:
                page_id = f"{uploaded_file.name}_p{chunk['page']}"
                ids.append(page_id)
                docs.append(chunk["text"])
                vecs.append(model_handler.get_text_embedding(chunk["text"]))
                metas.append({
                    "path": final_path,
                    "topic": best_topic,
                    "page": chunk["page"]
                })

            paper_collection.upsert(ids=ids, embeddings=vecs, documents=docs, metadatas=metas)
            st.success(f"âœ… {uploaded_file.name} -> å½’ç±»ä¸º **{best_topic}** (ç´¢å¼•äº† {len(chunks)} é¡µ)")

            os.unlink(tmp_path)
            progress_bar.progress((idx + 1) / len(uploaded_files))

# --- åŠŸèƒ½ 2: è¯­ä¹‰æ–‡çŒ®æœç´¢ ---
elif app_mode == "ğŸ” è¯­ä¹‰æ–‡çŒ®æœç´¢":
    st.title("ğŸ” æ·±åº¦è¯­ä¹‰æœç´¢")
    query = st.text_input("è¯·è¾“å…¥é—®é¢˜æˆ–å…³é”®è¯", "How does self-attention work?")
    top_k = st.slider("è¿”å›ç»“æœæ•°é‡", 1, 10, 3)

    if st.button("æœç´¢") or query:
        if not query:
            st.warning("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
        else:
            query_vec = model_handler.get_text_embedding(query)
            results = paper_collection.query(query_embeddings=[query_vec], n_results=top_k)

            if not results['ids'] or not results['ids'][0]:
                st.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœã€‚")
            else:
                for i, _ in enumerate(results['ids'][0]):
                    meta = results['metadatas'][0][i]
                    snippet = results['documents'][0][i]
                    # score = results['distances'][0][i] 
                    
                    with st.container():
                        st.markdown(f"### ğŸ“„ ç»“æœ {i+1}: {os.path.basename(meta.get('path', 'Unknown'))}")
                        col1, col2 = st.columns([1, 4])
                        with col1:
                            st.info(f"**Topic**: {meta.get('topic', 'N/A')}\n\n**Page**: {meta.get('page', 'N/A')}")
                        with col2:
                            st.markdown(f"> ...{snippet[:500]}...")
                        st.divider()

# --- åŠŸèƒ½ 3: ä»¥æ–‡æœå›¾ ---
elif app_mode == "ğŸ–¼ï¸ ä»¥æ–‡æœå›¾":
    st.title("ğŸ–¼ï¸ æ™ºèƒ½å›¾ç‰‡æ£€ç´¢")

    if st.sidebar.button("é‡å»ºå›¾ç‰‡ç´¢å¼• (æ‰«æ data/ ç›®å½•)"):
        with st.spinner("æ­£åœ¨æ‰«æå›¾ç‰‡..."):
            image_dir = "data"
            valid_exts = ['.jpg', '.jpeg', '.png']
            count = 0
            for root, _, files in os.walk(image_dir):
                for file in files:
                    if any(file.lower().endswith(ext) for ext in valid_exts):
                        full_path = os.path.join(root, file)
                        try:
                            img = Image.open(full_path)
                            vec = model_handler.get_image_embedding(img)
                            image_collection.upsert(ids=[file], embeddings=[vec], metadatas=[{"path": full_path}])
                            count += 1
                        except: pass
            st.sidebar.success(f"æˆåŠŸç´¢å¼• {count} å¼ å›¾ç‰‡ï¼")

    query = st.text_input("æè¿°ä½ æƒ³æ‰¾çš„å›¾ç‰‡", "A diagram of transformer architecture")
    
    if query:
        query_vec = model_handler.get_text_for_image_embedding(query)
        results = image_collection.query(query_embeddings=[query_vec], n_results=4)

        if not results['ids'] or not results['ids'][0]:
            st.info("æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ã€‚è¯·ç¡®ä¿ data ç›®å½•ä¸‹æœ‰å›¾ç‰‡å¹¶å·²ç‚¹å‡»å·¦ä¾§'é‡å»ºç´¢å¼•'ã€‚")
        else:
            cols = st.columns(2)
            for i, doc_id in enumerate(results['ids'][0]):
                meta = results['metadatas'][0][i]
                img_path = meta['path']
                
                with cols[i % 2]:
                    if os.path.exists(img_path):
                        st.image(img_path, caption=f"{doc_id} (Path: {img_path})", use_container_width=True)
                    else:
                        st.error(f"å›¾ç‰‡ä¸¢å¤±: {img_path}")