import gradio as gr
import os
import chromadb
from PIL import Image
import numpy as np
import shutil

# å¯¼å…¥ä½ ç°æœ‰çš„åç«¯æ¨¡å—
# ç¡®ä¿ç›®å½•ä¸‹æœ‰ model_loader.py å’Œ utils.py
from model_loader import EmbeddingModel
from utils import extract_text_with_page_numbers, move_file_to_category

# --- å…¨å±€èµ„æºåŠ è½½ ---
print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®åº“...")
try:
    # åŠ è½½æ¨¡å‹
    model_handler = EmbeddingModel()
    
    # è¿æ¥æ•°æ®åº“
    client = chromadb.PersistentClient(path="./db")
    paper_collection = client.get_or_create_collection(name="papers")
    image_collection = client.get_or_create_collection(name="images")
    print("æ¨¡å‹ä¸æ•°æ®åº“åŠ è½½å®Œæ¯•ï¼")
except Exception as e:
    print(f"åˆå§‹åŒ–å¤±è´¥: {e}")

# --- åŠŸèƒ½å‡½æ•°å®šä¹‰ ---

def process_upload(file_obj, topics_str):
    """å¤„ç†è®ºæ–‡ä¸Šä¼ """
    if file_obj is None:
        return "è¯·å…ˆä¸Šä¼ æ–‡ä»¶"
    
    # Gradio ä¼ å…¥çš„ file_obj.name å°±æ˜¯ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ Gradio (3.x vs 4.x)
    tmp_path = file_obj.name if hasattr(file_obj, 'name') else file_obj
    
    # 1. æå–æ–‡æœ¬
    chunks = extract_text_with_page_numbers(tmp_path)
    if not chunks:
        return "æ— æ³•æå–æ–‡æœ¬ï¼Œè¯·æ£€æŸ¥ PDF æ–‡ä»¶ã€‚"
    
    # 2. ç¡®å®šåˆ†ç±»
    # å–å‰3é¡µåšåˆ†ç±»
    summary_text = " ".join([c["text"] for c in chunks[:3]])
    summary_vec = model_handler.get_text_embedding(summary_text)

    best_topic = "Uncategorized"
    if topics_str:
        t_list = topics_str.split(',')
        t_vecs = model_handler.text_model.encode(t_list)
        # è®¡ç®—ç›¸ä¼¼åº¦
        scores = [np.dot(t_v, summary_vec) for t_v in t_vecs]
        best_topic = t_list[np.argmax(scores)]

    # 3. ä¿å­˜æ–‡ä»¶
    target_dir = os.path.join("data", best_topic)
    os.makedirs(target_dir, exist_ok=True)
    
    # è·å–åŸå§‹æ–‡ä»¶å (Gradio ä¼šé‡å‘½åä¸´æ—¶æ–‡ä»¶ï¼Œæˆ‘ä»¬å°½é‡è¿˜åŸ)
    original_name = os.path.basename(tmp_path)
    if hasattr(file_obj, 'orig_name'): # æŸäº› Gradio ç‰ˆæœ¬
        original_name = file_obj.orig_name
        
    final_path = os.path.join(target_dir, original_name)
    shutil.copy(tmp_path, final_path)

    # 4. å­˜å…¥æ•°æ®åº“
    ids, docs, vecs, metas = [], [], [], []
    for chunk in chunks:
        page_id = f"{original_name}_p{chunk['page']}"
        ids.append(page_id)
        docs.append(chunk["text"])
        vecs.append(model_handler.get_text_embedding(chunk["text"]))
        metas.append({
            "path": final_path,
            "topic": best_topic,
            "page": chunk["page"]
        })

    paper_collection.upsert(ids=ids, embeddings=vecs, documents=docs, metadatas=metas)
    
    return f"âœ… æˆåŠŸï¼å½’ç±»ä¸º: {best_topic}\nå·²ç´¢å¼• {len(chunks)} é¡µã€‚\nä¿å­˜è·¯å¾„: {final_path}"

def search_docs(query, top_k):
    """è¯­ä¹‰æœç´¢"""
    if not query: return "è¯·è¾“å…¥é—®é¢˜"
    
    query_vec = model_handler.get_text_embedding(query)
    results = paper_collection.query(query_embeddings=[query_vec], n_results=int(top_k))

    if not results['ids'] or not results['ids'][0]:
        return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
    
    output = ""
    for i, _ in enumerate(results['ids'][0]):
        meta = results['metadatas'][0][i]
        snippet = results['documents'][0][i]
        path = meta.get('path', 'Unknown')
        topic = meta.get('topic', 'N/A')
        page = meta.get('page', 'N/A')
        
        output += f"### ğŸ“„ ç»“æœ {i+1}: {os.path.basename(path)}\n"
        output += f"**Topic**: {topic} | **Page**: {page}\n\n"
        output += f"> ...{snippet[:300]}...\n"
        output += "---\n"
    return output

def index_local_images():
    """ç´¢å¼• data ç›®å½•å›¾ç‰‡"""
    image_dir = "data"
    valid_exts = ['.jpg', '.jpeg', '.png']
    count = 0
    for root, _, files in os.walk(image_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in valid_exts):
                full_path = os.path.join(root, file)
                try:
                    img = Image.open(full_path)
                    vec = model_handler.get_image_embedding(img)
                    image_collection.upsert(ids=[file], embeddings=[vec], metadatas=[{"path": full_path}])
                    count += 1
                except: pass
    return f"âœ… é‡å»ºç´¢å¼•å®Œæˆï¼å…±ç´¢å¼• {count} å¼ å›¾ç‰‡ã€‚"

def search_imgs(query):
    """ä»¥æ–‡æœå›¾"""
    if not query: return []
    
    query_vec = model_handler.get_text_for_image_embedding(query)
    results = image_collection.query(query_embeddings=[query_vec], n_results=4)
    
    images = []
    if results['ids'] and results['ids'][0]:
        for i, _ in enumerate(results['ids'][0]):
            meta = results['metadatas'][0][i]
            img_path = meta['path']
            if os.path.exists(img_path):
                # Gradio Gallery æ¥å— (image_path, caption) çš„å…ƒç»„åˆ—è¡¨
                images.append((img_path, f"Result {i+1}"))
    return images

# --- æ„å»º UI ---
with gr.Blocks(title="å¤šæ¨¡æ€ AI åŠ©æ‰‹") as demo:
    gr.Markdown("# ğŸ¤– æœ¬åœ°å¤šæ¨¡æ€ AI æ™ºèƒ½åŠ©æ‰‹")
    
    with gr.Tab("ğŸ“„ è®ºæ–‡ä¸Šä¼ ä¸åˆ†ç±»"):
        gr.Markdown("ä¸Šä¼  PDF æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æè¯­ä¹‰å¹¶å½’æ¡£ã€‚")
        with gr.Row():
            file_input = gr.File(label="ä¸Šä¼  PDF", file_types=[".pdf"])
            topics_input = gr.Textbox(label="åˆ†ç±»ä¸»é¢˜ (é€—å·åˆ†éš”)", value="CV,NLP,Agent,RL")
        upload_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
        upload_output = gr.Textbox(label="å¤„ç†ç»“æœ")
        
        upload_btn.click(process_upload, inputs=[file_input, topics_input], outputs=upload_output)

    with gr.Tab("ğŸ” è¯­ä¹‰æ–‡çŒ®æœç´¢"):
        gr.Markdown("è¾“å…¥è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œæœç´¢ç›¸å…³è®ºæ–‡ç‰‡æ®µã€‚")
        search_input = gr.Textbox(label="è¾“å…¥é—®é¢˜", placeholder="ä¾‹å¦‚: How does transformer work?")
        top_k_slider = gr.Slider(minimum=1, maximum=10, value=3, step=1, label="è¿”å›ç»“æœæ•°é‡")
        search_btn = gr.Button("æœç´¢")
        search_output = gr.Markdown(label="æœç´¢ç»“æœ")
        
        search_btn.click(search_docs, inputs=[search_input, top_k_slider], outputs=search_output)

    with gr.Tab("ğŸ–¼ï¸ ä»¥æ–‡æœå›¾"):
        gr.Markdown("è¾“å…¥æè¿°æœç´¢æœ¬åœ°å›¾ç‰‡ã€‚è¯·ç¡®ä¿ data ç›®å½•ä¸‹æœ‰å›¾ç‰‡ã€‚")
        with gr.Row():
            idx_btn = gr.Button("ğŸ”„ é‡å»ºå›¾ç‰‡ç´¢å¼• (æ‰«æ data/ ç›®å½•)")
            idx_output = gr.Textbox(label="ç´¢å¼•çŠ¶æ€", show_label=False)
        
        idx_btn.click(index_local_images, outputs=idx_output)
        
        img_query = gr.Textbox(label="å›¾ç‰‡æè¿°", placeholder="ä¾‹å¦‚: A diagram of neural network")
        img_btn = gr.Button("æœå›¾")
        gallery = gr.Gallery(label="æœç´¢ç»“æœ", columns=2, height="auto")
        
        img_btn.click(search_imgs, inputs=img_query, outputs=gallery)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)